{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0519f570",
   "metadata": {},
   "source": [
    "## Predicting Health Professional Shortage Areas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57894746",
   "metadata": {},
   "source": [
    "HPSA, short for \"Health Professional Shortage Area\", is a federal government term for a specific region or location that is experiencing a shortage of healthcare professionals. Every so often, HPSA Scores are developed by the National Health Service Corps in determining priority of assignment of clinicians to certain areas. The scores range from 0 to 26 where the higher the score, the greater the priority. In this project, I will train a Machine Learning model to predict Primary Care HPSA scores based on various location metrics (county income, unemployment rate, etc) using features taken from other government websites such as the US Bureau of Labor Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73d6ed",
   "metadata": {},
   "source": [
    "# Step 1: ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc2928",
   "metadata": {},
   "source": [
    "This data is taken from the https://data.hrsa.gov/ website in individual XLSX files by state. Unfortunately, each state's data is separately stored, meaning we will have to extract and load each state iteratively. Let's take a peek at a single state for now loaded in a variable peek_data, that encompasses the data for Alabama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8c343c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_197ee_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Discipline</th>        <th class=\"col_heading level0 col1\" >HPSA ID</th>        <th class=\"col_heading level0 col2\" >HPSA Name</th>        <th class=\"col_heading level0 col3\" >Designation Type</th>        <th class=\"col_heading level0 col4\" >Primary State Name</th>        <th class=\"col_heading level0 col5\" >County Name</th>        <th class=\"col_heading level0 col6\" >HPSA FTE Short</th>        <th class=\"col_heading level0 col7\" >HPSA Score</th>        <th class=\"col_heading level0 col8\" >Status</th>        <th class=\"col_heading level0 col9\" >Rural Status</th>        <th class=\"col_heading level0 col10\" >Designation Date</th>        <th class=\"col_heading level0 col11\" >Update Date</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_197ee_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_197ee_row0_col0\" class=\"data row0 col0\" >Primary Care</td>\n",
       "                        <td id=\"T_197ee_row0_col1\" class=\"data row0 col1\" >1016018546</td>\n",
       "                        <td id=\"T_197ee_row0_col2\" class=\"data row0 col2\" >LI-Marion County</td>\n",
       "                        <td id=\"T_197ee_row0_col3\" class=\"data row0 col3\" >Low Income Population HPSA</td>\n",
       "                        <td id=\"T_197ee_row0_col4\" class=\"data row0 col4\" >Alabama</td>\n",
       "                        <td id=\"T_197ee_row0_col5\" class=\"data row0 col5\" >Marion County, AL</td>\n",
       "                        <td id=\"T_197ee_row0_col6\" class=\"data row0 col6\" >1.673</td>\n",
       "                        <td id=\"T_197ee_row0_col7\" class=\"data row0 col7\" >14</td>\n",
       "                        <td id=\"T_197ee_row0_col8\" class=\"data row0 col8\" >Designated</td>\n",
       "                        <td id=\"T_197ee_row0_col9\" class=\"data row0 col9\" >Rural</td>\n",
       "                        <td id=\"T_197ee_row0_col10\" class=\"data row0 col10\" >06/22/2022</td>\n",
       "                        <td id=\"T_197ee_row0_col11\" class=\"data row0 col11\" >06/22/2022</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_197ee_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_197ee_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "                        <td id=\"T_197ee_row1_col1\" class=\"data row1 col1\" >Component State Name</td>\n",
       "                        <td id=\"T_197ee_row1_col2\" class=\"data row1 col2\" >Component County Name</td>\n",
       "                        <td id=\"T_197ee_row1_col3\" class=\"data row1 col3\" >Component Name</td>\n",
       "                        <td id=\"T_197ee_row1_col4\" class=\"data row1 col4\" >Component Type</td>\n",
       "                        <td id=\"T_197ee_row1_col5\" class=\"data row1 col5\" >Component GEOID</td>\n",
       "                        <td id=\"T_197ee_row1_col6\" class=\"data row1 col6\" >Component Rural Status</td>\n",
       "                        <td id=\"T_197ee_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "                        <td id=\"T_197ee_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "                        <td id=\"T_197ee_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "                        <td id=\"T_197ee_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "                        <td id=\"T_197ee_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_197ee_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_197ee_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "                        <td id=\"T_197ee_row2_col1\" class=\"data row2 col1\" >Alabama</td>\n",
       "                        <td id=\"T_197ee_row2_col2\" class=\"data row2 col2\" >Marion</td>\n",
       "                        <td id=\"T_197ee_row2_col3\" class=\"data row2 col3\" >Marion</td>\n",
       "                        <td id=\"T_197ee_row2_col4\" class=\"data row2 col4\" >Single County</td>\n",
       "                        <td id=\"T_197ee_row2_col5\" class=\"data row2 col5\" >01093</td>\n",
       "                        <td id=\"T_197ee_row2_col6\" class=\"data row2 col6\" >Rural</td>\n",
       "                        <td id=\"T_197ee_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "                        <td id=\"T_197ee_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "                        <td id=\"T_197ee_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "                        <td id=\"T_197ee_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "                        <td id=\"T_197ee_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_197ee_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_197ee_row3_col0\" class=\"data row3 col0\" >Primary Care</td>\n",
       "                        <td id=\"T_197ee_row3_col1\" class=\"data row3 col1\" >1019011119</td>\n",
       "                        <td id=\"T_197ee_row3_col2\" class=\"data row3 col2\" >Perry County</td>\n",
       "                        <td id=\"T_197ee_row3_col3\" class=\"data row3 col3\" >High Needs Geographic HPSA</td>\n",
       "                        <td id=\"T_197ee_row3_col4\" class=\"data row3 col4\" >Alabama</td>\n",
       "                        <td id=\"T_197ee_row3_col5\" class=\"data row3 col5\" >Perry County, AL</td>\n",
       "                        <td id=\"T_197ee_row3_col6\" class=\"data row3 col6\" >0.87</td>\n",
       "                        <td id=\"T_197ee_row3_col7\" class=\"data row3 col7\" >19</td>\n",
       "                        <td id=\"T_197ee_row3_col8\" class=\"data row3 col8\" >Designated</td>\n",
       "                        <td id=\"T_197ee_row3_col9\" class=\"data row3 col9\" >Rural</td>\n",
       "                        <td id=\"T_197ee_row3_col10\" class=\"data row3 col10\" >01/15/1979</td>\n",
       "                        <td id=\"T_197ee_row3_col11\" class=\"data row3 col11\" >09/08/2021</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_197ee_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_197ee_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "                        <td id=\"T_197ee_row4_col1\" class=\"data row4 col1\" >Component State Name</td>\n",
       "                        <td id=\"T_197ee_row4_col2\" class=\"data row4 col2\" >Component County Name</td>\n",
       "                        <td id=\"T_197ee_row4_col3\" class=\"data row4 col3\" >Component Name</td>\n",
       "                        <td id=\"T_197ee_row4_col4\" class=\"data row4 col4\" >Component Type</td>\n",
       "                        <td id=\"T_197ee_row4_col5\" class=\"data row4 col5\" >Component GEOID</td>\n",
       "                        <td id=\"T_197ee_row4_col6\" class=\"data row4 col6\" >Component Rural Status</td>\n",
       "                        <td id=\"T_197ee_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "                        <td id=\"T_197ee_row4_col8\" class=\"data row4 col8\" >nan</td>\n",
       "                        <td id=\"T_197ee_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "                        <td id=\"T_197ee_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "                        <td id=\"T_197ee_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e654ab7e48>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "np.set_printoptions(threshold=np.inf) #allows for greater print capabilities for troubleshooting\n",
    "peek_data=pd.read_excel(\"utility/data/HPSAdata/Hpsa_Find_Export.xlsx\",index_col=None,header=3)\n",
    "#header is 3 since that is the row the column titles are stored. \n",
    "\n",
    "peek_data.head().style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640f201",
   "metadata": {},
   "source": [
    "Note above that there are various rows with extraneous information. However, the Component GEOID, a unique identifier for each county in the US also known as FIPS, is not extraneous and will need to be extracted. This is important since the GEOID is the identifier we will use to merge new features (eg. unemployment rates by county) into the dataset using SQL later. \n",
    "\n",
    "Closer review of the table shows that some FIPS codes not provided in lieu of ZIP codes, which are useless to us. Luckily, these entries also give us the county name alongside the ZIP code. Therefore, before we code a method to clean our data, we will create a dictionary to find FIPS codes from county names when they are not already provided. To do this, I have an excel worksheet copying the Wikipedia FIPS Table. Unfortunately, the FIPS codes are missing their leading zeroes and the county names all have the word 'county' after them, so we will quickly clean the csv here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a853d6",
   "metadata": {},
   "source": [
    "\n",
    "We'll first create a dictionary of state names to state abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93186cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map=pd.read_csv('utility/data/StateDict.csv')\n",
    "state_map.iloc[:,0]=state_map.iloc[:,0].apply(lambda x: re.sub(r'[^\\w\\s]','', str(x).casefold().strip()))\n",
    "state_map.iloc[:,1]=state_map.iloc[:,1].apply(lambda x: str(x).casefold())\n",
    "statedict=dict(zip(state_map.iloc[:,(0)],state_map.iloc[:,(1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e72a470",
   "metadata": {},
   "source": [
    "Let's talk about how to convert county names to FIPS codes. Unfortunately, county names are not unique. To ensure our data will match our keys in the future, any dictionary keys will consist of the first word (or if longer than one word, the first two words) in the county name with the state abbreviation to the end. \n",
    "\n",
    "eg. baldwinal : 01003, and baldwinga : 13009 for Baldwin County, Alabama, and Baldwin County, Georgia respectively\n",
    "\n",
    "and\n",
    "\n",
    "aleutianswestak and aleutianseastak for Aleutians West/East, AK (note how the two are redundant if only the first word is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae5711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatting our data to enter into a dictionary\n",
    "rawmap=pd.read_excel(\"utility/data/FIPSDict.xlsx\",header=0, dtype={'County':str,'State':str,'FIPS' : str})\n",
    "rawmap['State'].fillna(method='ffill',inplace=True)\n",
    "rawmap['State']=rawmap['State'].apply(lambda x: str(x).casefold())\n",
    "rawmap['FIPS']=rawmap['FIPS'].apply(lambda x: str(x).zfill(5))\n",
    "rawmap.dropna(inplace=True)\n",
    "\n",
    "\n",
    "for i in range(len(rawmap)):\n",
    "    rawmap['County'][i]=re.sub(r'[^\\w\\s]','', str(rawmap['County'][i]).casefold()).replace('county','')\n",
    "\n",
    "    split_string=rawmap['County'][i].split()\n",
    "    \n",
    "    if (len(split_string)>1): #If more than one word\n",
    "        rawmap['County'][i]=split_string[0]+split_string[1]\n",
    "    else:\n",
    "        rawmap['County'][i]=split_string[0].strip() #one word\n",
    "    \n",
    "    rawmap['State'][i]=statedict.get(rawmap['State'][i].strip().casefold())\n",
    "\n",
    "rawmap['key']=rawmap['County']+rawmap['State']\n",
    "\n",
    "FIPSDict=dict(zip(rawmap['key'],rawmap['FIPS']))\n",
    "FIPSDict['districtofdc']= '11001'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0686504a",
   "metadata": {},
   "source": [
    "Now that we have a dictionary of county names to FIPS codes, we can code in our general cleaning method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d318a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data): # drops unnecessary rows and columns and generates new GEOID column\n",
    "    \"\"\"\n",
    "    Clean function takes in HPSA data in the format found on hrsa.gov and extracts the FIPS codes from the table. The\n",
    "    method drops rows if they do not have a numeric target variable (HPSA score) and drops pre-defined features from\n",
    "    the table. It also creates a new column of FIPS codes. \n",
    "    \n",
    "    :param p1: Data to be cleaned.\n",
    "    :return: Data undergone processes as documented above.\n",
    "    \"\"\" \n",
    "    errorarray=([])\n",
    "    GeoIDs=[]\n",
    "    \n",
    "    for i in range(len(data['County Name'])): #locates all geolocation codes and truncates them at 5 digits\n",
    "        \n",
    "        string=str(data['County Name'][i]).casefold() #gets table title to determine if geolocation code was provided.\n",
    "        \n",
    "        if (('geoid' in string)): #Geolocation code was properly provided and added to new column\n",
    "            GeoIDs.append(data['County Name'][i+1][:5])\n",
    "            continue\n",
    "            \n",
    "        if (('zip' in string)): #ZIP code was provided. Geolocation code was found from county name. \n",
    "            StateAbbrev=str(data['Primary State Name'][i+1]).strip().replace(' ','')\n",
    "\n",
    "            string=re.sub(r'[^\\w\\s]','', str(data['HPSA FTE Short'][i+1]).casefold()).replace('county','')\n",
    "            split_string=str(data['HPSA FTE Short'][i+1]).split()\n",
    "\n",
    "            if (len(split_string)>1): #If more than one word\n",
    "                County=split_string[0]+split_string[1]\n",
    "            else:\n",
    "                County=split_string[0].strip() #one word\n",
    "                \n",
    "            key = str(re.sub(r'[^\\w\\s]', '',(County+StateAbbrev)).casefold().strip())\n",
    "            dictvalue=FIPSDict.get(key)\n",
    "            \n",
    "            if (dictvalue is not None):\n",
    "                GeoIDs.append(dictvalue)\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(\"Key not found in dictionary for \" + data['County Name'][i-1])\n",
    "                \n",
    "            \n",
    "            \n",
    "    data=data.loc[pd.to_numeric(data.iloc[:,7],errors='coerce').notna()]\n",
    "    #Converts HPSA scores to numeric values and drops all rows where the score is not numeric\n",
    "    #Dropped rows include titles and blank rows\n",
    "\n",
    "    data=data.reset_index(drop=True)\n",
    "    #renumbering our rows after dropping unnecessary ones\n",
    "\n",
    "    data=data.iloc[:,[2,3,4,5,7,9]]\n",
    "    #drops the ID, status, and two date categories, as these are logistical in nature.\n",
    "    #drops discipline since all pulled data is from Primary Care only\n",
    "    #Drops HPSA FTE Short since this only exists for regions experiencing dire shortages (And is therefore biased)\n",
    "    \n",
    "    #data['FIPS'] = GeoIDs \n",
    "    #Adds the geolocation codes (aka FIPS codes) as a column to the table\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8ff85c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_3ea4a_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >HPSA Name</th>        <th class=\"col_heading level0 col1\" >Designation Type</th>        <th class=\"col_heading level0 col2\" >Primary State Name</th>        <th class=\"col_heading level0 col3\" >County Name</th>        <th class=\"col_heading level0 col4\" >HPSA Score</th>        <th class=\"col_heading level0 col5\" >Rural Status</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3ea4a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_3ea4a_row0_col0\" class=\"data row0 col0\" >LI-Marion County</td>\n",
       "                        <td id=\"T_3ea4a_row0_col1\" class=\"data row0 col1\" >Low Income Population HPSA</td>\n",
       "                        <td id=\"T_3ea4a_row0_col2\" class=\"data row0 col2\" >Alabama</td>\n",
       "                        <td id=\"T_3ea4a_row0_col3\" class=\"data row0 col3\" >Marion County, AL</td>\n",
       "                        <td id=\"T_3ea4a_row0_col4\" class=\"data row0 col4\" >14</td>\n",
       "                        <td id=\"T_3ea4a_row0_col5\" class=\"data row0 col5\" >Rural</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ea4a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_3ea4a_row1_col0\" class=\"data row1 col0\" >Perry County</td>\n",
       "                        <td id=\"T_3ea4a_row1_col1\" class=\"data row1 col1\" >High Needs Geographic HPSA</td>\n",
       "                        <td id=\"T_3ea4a_row1_col2\" class=\"data row1 col2\" >Alabama</td>\n",
       "                        <td id=\"T_3ea4a_row1_col3\" class=\"data row1 col3\" >Perry County, AL</td>\n",
       "                        <td id=\"T_3ea4a_row1_col4\" class=\"data row1 col4\" >19</td>\n",
       "                        <td id=\"T_3ea4a_row1_col5\" class=\"data row1 col5\" >Rural</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ea4a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_3ea4a_row2_col0\" class=\"data row2 col0\" >Marengo County</td>\n",
       "                        <td id=\"T_3ea4a_row2_col1\" class=\"data row2 col1\" >High Needs Geographic HPSA</td>\n",
       "                        <td id=\"T_3ea4a_row2_col2\" class=\"data row2 col2\" >Alabama</td>\n",
       "                        <td id=\"T_3ea4a_row2_col3\" class=\"data row2 col3\" >Marengo County, AL</td>\n",
       "                        <td id=\"T_3ea4a_row2_col4\" class=\"data row2 col4\" >19</td>\n",
       "                        <td id=\"T_3ea4a_row2_col5\" class=\"data row2 col5\" >Rural</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ea4a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_3ea4a_row3_col0\" class=\"data row3 col0\" >Wilcox County</td>\n",
       "                        <td id=\"T_3ea4a_row3_col1\" class=\"data row3 col1\" >High Needs Geographic HPSA</td>\n",
       "                        <td id=\"T_3ea4a_row3_col2\" class=\"data row3 col2\" >Alabama</td>\n",
       "                        <td id=\"T_3ea4a_row3_col3\" class=\"data row3 col3\" >Wilcox County, AL</td>\n",
       "                        <td id=\"T_3ea4a_row3_col4\" class=\"data row3 col4\" >21</td>\n",
       "                        <td id=\"T_3ea4a_row3_col5\" class=\"data row3 col5\" >Rural</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3ea4a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_3ea4a_row4_col0\" class=\"data row4 col0\" >Bullock County</td>\n",
       "                        <td id=\"T_3ea4a_row4_col1\" class=\"data row4 col1\" >High Needs Geographic HPSA</td>\n",
       "                        <td id=\"T_3ea4a_row4_col2\" class=\"data row4 col2\" >Alabama</td>\n",
       "                        <td id=\"T_3ea4a_row4_col3\" class=\"data row4 col3\" >Bullock County, AL</td>\n",
       "                        <td id=\"T_3ea4a_row4_col4\" class=\"data row4 col4\" >22</td>\n",
       "                        <td id=\"T_3ea4a_row4_col5\" class=\"data row4 col5\" >Rural</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e6559615c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek_data=load(peek_data)\n",
    "peek_data.head().style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02000cd",
   "metadata": {},
   "source": [
    "As seen in the above, our data has been cleaned and a FIPS column has been added! FIPS is an identifier for the county that the facility is in - remember that it is not a unique identifier/primary key for each of our healthcare facilities themselves. Now that we've created and tested a method to appropriately clean and structure our datasets, we will proceed to wrangle all 50 state datasets together. I will also replace all the spaces in the column title with underscores and lowercase to make columns more consistent across this notebook and my SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b541a264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 datasets were successfully concatenated with a final shape of (6804, 6)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "directory = 'utility/data/HPSAdata'\n",
    "data = pd.DataFrame()\n",
    "counter=0 \n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    path = os.path.join(directory, filename) #generate file path\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        state_data=pd.read_excel(path,index_col=None,header=3) #import\n",
    "        state_data=load(state_data)\n",
    "        data=pd.concat([data,state_data]) #add to existing data\n",
    "        \n",
    "        counter+=1\n",
    "        \n",
    "data.columns = data.columns.str.replace(r\"\\s+\", '_') #changes column name spaces to underscores and lowercase\n",
    "data.columns=data.columns.str.casefold()\n",
    "\n",
    "print (str(counter) + ' datasets were successfully concatenated with a final shape of ' + str(data.shape))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27641e",
   "metadata": {},
   "source": [
    "Now that we have a pandas dataframe with all  the necessary base information, we will proceed to upload it to SQL (for storage and for later joins). Interested in how I set up the table? Check out my SQL Create Table command in the text file included in the repository. For the most part, however, most queries will be executed from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e156d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, String, Float\n",
    "\n",
    "#upload dataframe to SQL\n",
    "engine = create_engine('postgresql://postgres:sql@localhost/HPSA')\n",
    "\n",
    "data.to_sql('hpsadata', con=engine, if_exists='replace', index=False,\n",
    "            dtype={\"hpsa_score\": Integer()}) #naming the SQL Table HPSAdata\n",
    "\n",
    "#prepare Python query tool\n",
    "conn=pg2.connect(database='HPSA', user='postgres',password='sql')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4fcded",
   "metadata": {},
   "source": [
    "Now let's make sure that our dataframe was transferred properly and run a query from our notebook here. We're going to get a count of the number of rows in our SQL table and validate that against the shape of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT COUNT(*) FROM hpsadata\") #validate shape by comparing to previous cell\n",
    "print(\"SQL database size is \" + str(cur.fetchall()) + \" rows.\")\n",
    "print(\"Pandas Dataframe shape is \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1cae96",
   "metadata": {},
   "source": [
    "Now that our data has been cleaned and exported to a SQL database, we can now begin our EDA process using SQL Queries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240fb988",
   "metadata": {},
   "source": [
    "# Step 2: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526dd64",
   "metadata": {},
   "source": [
    "Let's begin exploring our data! First, let's take a look at the HPSA Designation Types. These are the 'reasons' why an area is determined to be low in Health Professionals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a03126",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "query = pd.read_sql_query('''SELECT DISTINCT(designation_type),COUNT(*) as frequency\n",
    "                       FROM hpsadata \n",
    "                       GROUP BY designation_type \n",
    "                       ORDER BY COUNT(*);''', \n",
    "                       engine)\n",
    "\n",
    "fig = px.bar(query, y='designation_type', x='frequency', orientation='h',\n",
    "            color=\"frequency\", color_continuous_scale='blugrn',\n",
    "            range_x=(0,1600),\n",
    "            title='Frequency of Rural Classifications in HPSA Data')\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Frequency of HPSA Designation Types in HPSA Data\",\n",
    "    xaxis_title=\"Frequency\",\n",
    "    yaxis_title=None,\n",
    "    yaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = list(range(19)),\n",
    "        ticktext=(query['designation_type'].str[:40]+\"...\").tolist() #truncates ylabel to 40 char\n",
    "        ),\n",
    "    xaxis=dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals=np.arange(0,1600,step=100)),\n",
    "    legend_title=\"Legend Title\",\n",
    "    font=dict(\n",
    "        family=\"Arial\",\n",
    "        size=12,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show('jpeg',width=1024, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2afb9",
   "metadata": {},
   "source": [
    "Note that the y axis labels are truncated due to length but can be viewed by mousing over the bar in the plot. \n",
    "\n",
    "Looking at our bar graph above, it appears that the most important causes of shortage areas is low income, rurality, geographic location, Native American areas, and Federally Qualified Health Centers - Providers receiving funds from the federal government to provide primary care in shortage areas. Because of this, features that we might consider adding include average income, if a center serves a reservation or other Native American population, and government funding in the area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = pd.read_sql_query('''SELECT DISTINCT(rural_status), COUNT(*) AS frequency\n",
    "                             FROM hpsadata\n",
    "                             GROUP BY rural_status\n",
    "                             ORDER BY COUNT(*)''', \n",
    "                             engine)\n",
    "\n",
    "fig = px.bar(query, y='frequency', x='rural_status', orientation='v',color_discrete_sequence=[\"mediumseagreen\"],\n",
    "            range_x=(-1,3),\n",
    "            title='Frequency of Rural Classifications in HPSA Data')\n",
    "\n",
    "\n",
    "\n",
    "fig.show('jpeg',width=1024, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0fea8",
   "metadata": {},
   "source": [
    "It appears that the majority of the facilities in the dataset are rural. Additional parameters may be needed to distinguish shortage areas within rural communities since rurality is not a very strongly unique feature in this dataset.\n",
    "\n",
    "Now, let's look at our target variable, the HPSA Score. \n",
    "\n",
    "*Note: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798cc202",
   "metadata": {},
   "outputs": [],
   "source": [
    "query= pd.read_sql_query('''SELECT hpsa_score FROM hpsadata ORDER BY hpsa_score''', \n",
    "                        engine)\n",
    "\n",
    "fig=px.histogram(query, title='Histogram of HPSA Score in HPSA data')\n",
    "fig.update_xaxes(tickvals=np.arange(0,26,step=2),showgrid=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"HPSA Score\",\n",
    "    yaxis_title='Frequency',\n",
    "    font=dict(\n",
    "        family=\"Arial\",\n",
    "        size=12,\n",
    "    )\n",
    ")\n",
    "fig.show('jpeg',width=1024, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059ce1b",
   "metadata": {},
   "source": [
    "The  distribution of HPSA Scores appears to be a distribution skewed towards  the right. There's an interesting island at HPSA Score = 3, but otherwise, the mode is 16 and the average is around 14 - nothing terrifically remarkable. Let's also take a look at these scores in terms of geolocation! \n",
    "\n",
    "Let's first import some some geojsons containing county borders so that we can seperate individual counties on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f71596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26498404",
   "metadata": {},
   "source": [
    "And now, let's create a chloropleth with our data by displaying the average HPSA score per county! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ef6fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query= pd.read_sql_query('''SELECT DISTINCT(FIPS), AVG(hpsa_score) as \"Average HPSA Score\"\n",
    "                        FROM hpsadata \n",
    "                        GROUP BY FIPS''', \n",
    "                        engine)\n",
    "\n",
    "fig = px.choropleth(query,\n",
    "                    locations='fips', \n",
    "                    geojson=counties,\n",
    "                    color='Average HPSA Score',\n",
    "                    color_continuous_scale=\"\",\n",
    "                    scope=\"usa\",\n",
    "                    )\n",
    "fig.update_layout(\n",
    "    title='Average HPSA Score by County',\n",
    "    font=dict(\n",
    "        size=30\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show('jpeg',width=2000,height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59411d",
   "metadata": {},
   "source": [
    "And here we have the average HPSA score by county! Feel free to zoom in and take a closer look. The color is scaled to the average HPSA score value - a higher score (higher deficit of professionals) is more yellow and a lower score is more purple. Now that we have a good idea of what our task is, let's start building features to train our prediction model on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169ada3",
   "metadata": {},
   "source": [
    "# Step 3: Feature Engineering/Feature ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d41c664",
   "metadata": {},
   "source": [
    "This section is going to be a lot of grunt work coding. As mentioned before, I am sourcing all of the features myself, so the following section is just me reading and cleaning various file types and uploading them to SQL. *I will join and visualize them after the next text box, so feel free to just skip until there.* So far, in respective order (so you can skip them if you're so inclined), I have the features:\n",
    "\n",
    "- 1-2. Unemployment Rates and Labor Force from the Bureau of Labor Statistics\n",
    "\n",
    "- 3. Personal Income from the Bureau of Economic Analysis\n",
    "\n",
    "- 4. Median Age from the US Census Bureau\n",
    "\n",
    "- 5. Native American Populations per County from US Census Bureau\n",
    "\n",
    "- 6-8. Heart disease, Diabetes, and Obesity Prevalences From CDC PLACES\n",
    "\n",
    "- 9. Poverty Prevalences from US Census Bureau\n",
    "\n",
    "- 10-13. Nursing Home Staffing (Nurse Aide, LPN, RN, PT) from the Centers of Medicare and Medicaid Services\n",
    "\n",
    "- 14. Number of people incarcerated from The Marshall Project\n",
    "\n",
    "- 15. Number of migrant farm workers and dependents from NCFH.\n",
    "    - NOTE: Access to this dataset is restricted. This dataset is NOT included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unemployment and Labor Force\n",
    "#Data cleaned by target feature. FIPS codes concatenated from existing. Columns renamed. Uploaded to SQL.\n",
    "\n",
    "featuredata=pd.read_excel(\"utility/data/FeatureData/Unemployment(laucntycur14).xlsx\",header=4,\n",
    "                         dtype={'State Fips': String,'County Fips':String})\n",
    "featuredata=featuredata.loc[pd.to_numeric(featuredata.iloc[:,7],errors='coerce').notna()] #dropping non-numeric targets\n",
    "featuredata['FIPS']=featuredata['State Fips'] + featuredata['County Fips']\n",
    "\n",
    "#clean column names\n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "featuredata=featuredata[['labor_force','unemployment_rate','fips']]\n",
    "\n",
    "featuredata.to_sql('unemploymentdata', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728348b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Income\n",
    "#Data cleaned by target feature. Columns renamed. County names encoded to FIPS. Uploaded to SQL. \n",
    "\n",
    "featuredata=pd.read_excel(\"utility/data/FeatureData/Income(lapi1121).xlsx\", header=3)\n",
    "featuredata=featuredata.loc[pd.to_numeric(featuredata.iloc[:,1],errors='coerce').notna()] #drop non-numeric\n",
    "featuredata=featuredata.reset_index(drop=True) \n",
    "\n",
    "#clean column names\n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "featuredata.rename(columns={\"county_name\":\"fips\"},inplace=True)\n",
    "featuredata=featuredata[['income','fips']]\n",
    "\n",
    "for i in range(len(featuredata['fips'])): #County Name to FIPS Codes\n",
    "        CountyName = re.sub(r'[^\\w\\s]', '',str(featuredata['fips'][i]).split()[0]).casefold()\n",
    "        dictvalue=FIPSDict.get(CountyName)\n",
    "        featuredata['fips'][i]=dictvalue\n",
    "\n",
    "print(featuredata)\n",
    "featuredata.to_sql('incomedata', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74a7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Population\n",
    "#Data cleaned by target feature. Columns renamed. County names encoded to FIPS. Uploaded to SQL.\n",
    "\n",
    "featuredata=pd.read_excel(\"utility/data/FeatureData/Population(co-est2021-pop).xlsx\",header=2)\n",
    "featuredata=featuredata.loc[pd.to_numeric(featuredata.iloc[:,1],errors='coerce').notna()] #drop non-numeric\n",
    "featuredata=featuredata.reset_index(drop=True) \n",
    "\n",
    "#clean column names\n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "featuredata.rename(columns={\"geographic_area\":\"fips\",'april_1,_2020_estimates_base':'population'},inplace=True)\n",
    "featuredata=featuredata.loc[:,('population','fips')]\n",
    "\n",
    "for i in range(len(featuredata['fips'])): #County Name to FIPS Codes\n",
    "        CountyName = re.sub(r'[^\\w\\s]', '',str(featuredata['fips'][i]).split()[0]).casefold()\n",
    "        dictvalue=FIPSDict.get(CountyName)\n",
    "        featuredata.loc[i,['fips']]=dictvalue\n",
    "        \n",
    "featuredata.to_sql('populationdata', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b01a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Native American\n",
    "#Data cleaned by provided categories. Columns renamed. County names encoded to FIPS. Uploaded to SQL.  \n",
    "\n",
    "featuredata=pd.read_csv(\"utility/data/FeatureData/AIAN(co-est00int-sexracehisp).csv\",\n",
    "                       engine='python',encoding='latin1')\n",
    "featuredata=featuredata[featuredata['SEX']==0] # all sexes\n",
    "featuredata=featuredata[featuredata['ORIGIN']==0] # all origins\n",
    "featuredata=featuredata[featuredata['RACE']==3] # Native American only\n",
    "\n",
    "featuredata=featuredata.loc[:,('CTYNAME','POPESTIMATE2010')]\n",
    "featuredata=featuredata.loc[pd.to_numeric(featuredata.iloc[:,1],errors='coerce').notna()] #drop non-numeric\n",
    "featuredata=featuredata.reset_index(drop=True) \n",
    "featuredata.rename(columns={\"CTYNAME\":\"fips\",'POPESTIMATE2010':'AIANpop'},inplace=True)\n",
    "\n",
    "for i in range(len(featuredata['fips'])): #County Name to FIPS Codes\n",
    "        CountyName = re.sub(r'[^\\w\\s]', '',str(featuredata['fips'][i]).split()[0]).casefold()\n",
    "        dictvalue=FIPSDict.get(CountyName)\n",
    "        featuredata.loc[i,['fips']]=dictvalue\n",
    "        \n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "\n",
    "featuredata.to_sql('aiandata', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Places\n",
    "#Columns renamed. FIPS provided. Uploaded to SQL. \n",
    "#Note: In proper join format for SQL despite appearing incredibly messy. Clean on SQL later.\n",
    "\n",
    "featuredata=pd.read_csv(\"utility/data/FeatureData/PLACES.csv\",\n",
    "                       dtype={'LocationID':str})\n",
    "\n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "featuredata.rename(columns={'locationid':'fips'},inplace=True)\n",
    "featuredata=featuredata.loc[:,('locationname','data_value','measureid','datavaluetypeid','fips')]\n",
    "\n",
    "featuredata.to_sql('places', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poverty\n",
    "#FIPS concatenated from existing. Columns renamed. Uploaded to SQL. \n",
    "\n",
    "\n",
    "featuredata=pd.read_csv(\"utility/data/FeatureData/Poverty(est20all).csv\",header=3,\n",
    "                       dtype={'State FIPS Code':str, 'County FIPS Code':str})\n",
    "\n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "featuredata.rename(columns={'poverty_estimate,_all_ages':'pov_num'},inplace=True)\n",
    "\n",
    "for i in range(len(featuredata)):\n",
    "    featuredata['state_fips_code'][i] = featuredata['state_fips_code'][i].zfill(2) \n",
    "    featuredata['county_fips_code'][i] = featuredata['county_fips_code'][i].zfill(3) \n",
    "    featuredata['pov_num'][i]=featuredata['pov_num'][i].replace(',', '')\n",
    "    \n",
    "featuredata['fips']=featuredata['state_fips_code']+featuredata['county_fips_code']\n",
    "featuredata=featuredata.loc[:,('pov_num','fips')]\n",
    "\n",
    "featuredata.to_sql('poverty', con=engine, if_exists='replace', index=False, dtype={'pov_num':Integer()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7848d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nursing Home (NH) Staffing\n",
    "#Columns renamed. County names encoded to FIPS. Uploaded to SQL.\n",
    "\n",
    "featuredata=pd.read_csv(\"utility/data/FeatureData/NHStaffing(NH_ProviderInfo_Jun2022).csv\",\n",
    "                        engine='python',encoding='latin1',header=0)\n",
    "\n",
    "featuredata.rename(columns={'Reported Nurse Aide Staffing Hours per Resident per Day':'aidehours',\n",
    "                           'Reported LPN Staffing Hours per Resident per Day':'lpnhours',\n",
    "                           'Reported RN Staffing Hours per Resident per Day':'rnhours',\n",
    "                           'Reported Physical Therapist Staffing Hours per Resident Per Day':'pthours',\n",
    "                           'Provider County Name':'fips'}, inplace=True)\n",
    "\n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "\n",
    "featuredata=featuredata.loc[:,('fips','aidehours','lpnhours','rnhours','pthours')]\n",
    "featuredata.dropna(inplace=True)\n",
    "featuredata=featuredata.reset_index(drop=True) \n",
    "\n",
    "for i in range(len(featuredata['fips'])): #County Name to FIPS Codes\n",
    "        CountyName = re.sub(r'[^\\w\\s]', '',str(featuredata['fips'][i]).split()[0]).casefold()\n",
    "        dictvalue=FIPSDict.get(CountyName)\n",
    "        featuredata.loc[i,['fips']]=dictvalue\n",
    "\n",
    "featuredata.to_sql('nhstaffing', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incarceration\n",
    "#Columns renamed. Uploaded to SQL. \n",
    "\n",
    "featuredata=pd.read_csv(\"utility/data/FeatureData/Prison(census_incarceration_TMP).csv\",\n",
    "                        engine='python',encoding='latin1',header=0, dtype={'FIPS':str})\n",
    "\n",
    "featuredata['prison_pct']=featuredata['incarcerated_20']/featuredata['total_population_20']\n",
    "featuredata.columns = featuredata.columns.str.replace(r\"\\s+\", '_')\n",
    "featuredata.columns=featuredata.columns.str.casefold()\n",
    "\n",
    "featuredata['fips']=featuredata['fips'].apply(lambda x: x.zfill(5))\n",
    "featuredata=featuredata.loc[:,('fips','prison_pct')]\n",
    "\n",
    "featuredata.to_sql('prison', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Migrant Farm Workers\n",
    "#NOT INCLUDED IN REPOSITORY\n",
    "#Joined 50 state files. Renamed Columns. County names encoded to FIPS. Uploaded to SQL.\n",
    "\n",
    "directory = 'C://Users/vsiu8/NCFH Data'\n",
    "featuredata = pd.DataFrame()\n",
    "counter=0 \n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    path = os.path.join(directory, filename) #generate file path\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        state_data=pd.read_csv(path,index_col=None) #import\n",
    "        featuredata=pd.concat([featuredata,state_data]) #add to existing data        \n",
    "        counter+=1\n",
    "        \n",
    "featuredata.rename(columns={'county':'fips', 'Total Dependents':'farmwrkrs'}, inplace=True)\n",
    "featuredata=featuredata.loc[:,('fips','farmwrkrs')]\n",
    "featuredata=featuredata.reset_index(drop=True) \n",
    "\n",
    "for i in range(len(featuredata['fips'])): #County Name to FIPS Codes\n",
    "        CountyName = re.sub(r'[^\\w\\s]', '',str(featuredata['fips'][i]).split()[0]).casefold()\n",
    "        dictvalue=FIPSDict.get(CountyName)\n",
    "        featuredata.loc[i,['fips']]=dictvalue\n",
    "        \n",
    "featuredata.to_sql('farmers', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecaceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOINING THE FEATUREDATA\n",
    "\n",
    "query= pd.read_sql_query('''WITH places_chd AS\n",
    "(SELECT pl.data_value as chd_pct, pl.fips\n",
    "FROM places pl\n",
    "WHERE pl.measureid = 'CHD'),\n",
    "\n",
    "places_obesity AS\n",
    "(SELECT pl.data_value as obesity_pct, pl.fips\n",
    "FROM places pl\n",
    "WHERE pl.measureid = 'OBESITY'),\n",
    "\n",
    "places_diabetes AS\n",
    "(SELECT pl.data_value as diabetes_pct, pl.fips\n",
    "FROM places pl\n",
    "WHERE pl.measureid = 'DIABETES'),\n",
    "\n",
    "avg_nursehrs AS\n",
    "(SELECT nh.fips, AVG(nh.aidehours) as avg_aide, AVG(nh.lpnhours) as avg_lpn,\n",
    "AVG(nh.rnhours) as avg_rn,AVG(nh.pthours) as avg_pt\n",
    "FROM nhstaffing nh\n",
    "GROUP BY nh.fips)\n",
    "\n",
    "\n",
    "SELECT u.fips, u.labor_force/pop.population as labor_force_pct, u.unemployment_rate, \n",
    "        i.income, pop.population, a.aianpop/pop.population as aian_pct, \n",
    "        places_chd.chd_pct, places_obesity.obesity_pct, places_diabetes.diabetes_pct, \n",
    "        pov_num/pop.population as pov_pct, nhrs.avg_aide, nhrs.avg_lpn,\n",
    "        nhrs.avg_rn,nhrs.avg_pt,pr.prison_pct, f.farmwrkrs\n",
    "FROM unemploymentdata u\n",
    "LEFT OUTER JOIN incomedata i\n",
    "ON u.fips = i.fips\n",
    "LEFT OUTER JOIN populationdata pop\n",
    "ON u.fips = pop.fips\n",
    "LEFT OUTER JOIN aiandata a\n",
    "ON u.fips =a.fips\n",
    "LEFT OUTER JOIN places_chd\n",
    "ON u.fips = places_chd.fips\n",
    "LEFT OUTER JOIN places_obesity\n",
    "ON u.fips = places_obesity.fips\n",
    "LEFT OUTER JOIN places_diabetes\n",
    "ON u.fips = places_diabetes.fips\n",
    "LEFT OUTER JOIN poverty pov\n",
    "ON  u.fips = pov.fips\n",
    "LEFT OUTER JOIN avg_nursehrs nhrs\n",
    "ON  u.fips=pov.fips\n",
    "LEFT OUTER JOIN prison pr\n",
    "ON u.fips=pr.fips\n",
    "LEFT OUTER JOIN farmers f\n",
    "ON  u.fips=f.fips''',\n",
    "engine)\n",
    "\n",
    "query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
